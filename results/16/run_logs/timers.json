{
    "name": "root",
    "gauges": {
        "ChompMan.Policy.Entropy.mean": {
            "value": 1.5990291833877563,
            "min": 1.5990291833877563,
            "max": 1.6016581058502197,
            "count": 2
        },
        "ChompMan.Policy.Entropy.sum": {
            "value": 47942.09375,
            "min": 47942.09375,
            "max": 48142.640625,
            "count": 2
        },
        "ChompMan.Step.mean": {
            "value": 59976.0,
            "min": 29994.0,
            "max": 59976.0,
            "count": 2
        },
        "ChompMan.Step.sum": {
            "value": 59976.0,
            "min": 29994.0,
            "max": 59976.0,
            "count": 2
        },
        "ChompMan.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": -4.1603007316589355,
            "min": -4.1603007316589355,
            "max": -0.9302228093147278,
            "count": 2
        },
        "ChompMan.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": -2030.2266845703125,
            "min": -2030.2266845703125,
            "max": -453.94873046875,
            "count": 2
        },
        "ChompMan.Policy.ExtrinsicValueEstimate.mean": {
            "value": -4.1603007316589355,
            "min": -4.1603007316589355,
            "max": -0.9302228093147278,
            "count": 2
        },
        "ChompMan.Policy.ExtrinsicValueEstimate.sum": {
            "value": -2030.2266845703125,
            "min": -2030.2266845703125,
            "max": -453.94873046875,
            "count": 2
        },
        "ChompMan.Environment.EpisodeLength.mean": {
            "value": 751.3589743589744,
            "min": 751.3589743589744,
            "max": 971.0666666666667,
            "count": 2
        },
        "ChompMan.Environment.EpisodeLength.sum": {
            "value": 29303.0,
            "min": 29132.0,
            "max": 29303.0,
            "count": 2
        },
        "ChompMan.Environment.CumulativeReward.mean": {
            "value": -120.82564611083421,
            "min": -120.82564611083421,
            "max": -107.87334046463171,
            "count": 2
        },
        "ChompMan.Environment.CumulativeReward.sum": {
            "value": -4712.200198322535,
            "min": -4712.200198322535,
            "max": -3236.2002139389515,
            "count": 2
        },
        "ChompMan.Policy.ExtrinsicReward.mean": {
            "value": -120.82564611083421,
            "min": -120.82564611083421,
            "max": -107.87334046463171,
            "count": 2
        },
        "ChompMan.Policy.ExtrinsicReward.sum": {
            "value": -4712.200198322535,
            "min": -4712.200198322535,
            "max": -3236.2002139389515,
            "count": 2
        },
        "ChompMan.Environment.GroupCumulativeReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 2
        },
        "ChompMan.Environment.GroupCumulativeReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 2
        },
        "ChompMan.Losses.PolicyLoss.mean": {
            "value": 0.023608502732693323,
            "min": 0.021271734428592027,
            "max": 0.023608502732693323,
            "count": 2
        },
        "ChompMan.Losses.PolicyLoss.sum": {
            "value": 0.07082550819807996,
            "min": 0.042543468857184054,
            "max": 0.07082550819807996,
            "count": 2
        },
        "ChompMan.Losses.ValueLoss.mean": {
            "value": 83.51088920169407,
            "min": 42.531933879852296,
            "max": 83.51088920169407,
            "count": 2
        },
        "ChompMan.Losses.ValueLoss.sum": {
            "value": 250.5326676050822,
            "min": 85.06386775970459,
            "max": 250.5326676050822,
            "count": 2
        },
        "ChompMan.Losses.BaselineLoss.mean": {
            "value": 87.8975342432658,
            "min": 43.68718843460083,
            "max": 87.8975342432658,
            "count": 2
        },
        "ChompMan.Losses.BaselineLoss.sum": {
            "value": 263.6926027297974,
            "min": 87.37437686920165,
            "max": 263.6926027297974,
            "count": 2
        },
        "ChompMan.Policy.LearningRate.mean": {
            "value": 0.0002975343408218866,
            "min": 0.0002975343408218866,
            "max": 0.00029907525030825,
            "count": 2
        },
        "ChompMan.Policy.LearningRate.sum": {
            "value": 0.0008926030224656599,
            "min": 0.0005981505006165,
            "max": 0.0008926030224656599,
            "count": 2
        },
        "ChompMan.Policy.Epsilon.mean": {
            "value": 0.19917811333333332,
            "min": 0.19917811333333332,
            "max": 0.19969175,
            "count": 2
        },
        "ChompMan.Policy.Epsilon.sum": {
            "value": 0.5975343399999999,
            "min": 0.3993835,
            "max": 0.5975343399999999,
            "count": 2
        },
        "ChompMan.Policy.Beta.mean": {
            "value": 0.004958987855333333,
            "min": 0.004958987855333333,
            "max": 0.004984618324999999,
            "count": 2
        },
        "ChompMan.Policy.Beta.sum": {
            "value": 0.014876963565999997,
            "min": 0.009969236649999998,
            "max": 0.014876963565999997,
            "count": 2
        },
        "ChompMan.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        },
        "ChompMan.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        },
        "Ghost.Policy.Entropy.mean": {
            "value": 1.5748571157455444,
            "min": 1.5748571157455444,
            "max": 1.5996296405792236,
            "count": 2
        },
        "Ghost.Policy.Entropy.sum": {
            "value": 47217.3671875,
            "min": 47217.3671875,
            "max": 48081.66796875,
            "count": 2
        },
        "Ghost.Step.mean": {
            "value": 59976.0,
            "min": 29994.0,
            "max": 59976.0,
            "count": 2
        },
        "Ghost.Step.sum": {
            "value": 59976.0,
            "min": 29994.0,
            "max": 59976.0,
            "count": 2
        },
        "Ghost.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": 18.95587921142578,
            "min": 2.2579712867736816,
            "max": 18.95587921142578,
            "count": 2
        },
        "Ghost.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": 9250.46875,
            "min": 1101.8900146484375,
            "max": 9250.46875,
            "count": 2
        },
        "Ghost.Policy.ExtrinsicValueEstimate.mean": {
            "value": 18.95587921142578,
            "min": 2.2579712867736816,
            "max": 18.95587921142578,
            "count": 2
        },
        "Ghost.Policy.ExtrinsicValueEstimate.sum": {
            "value": 9250.46875,
            "min": 1101.8900146484375,
            "max": 9250.46875,
            "count": 2
        },
        "Ghost.Environment.EpisodeLength.mean": {
            "value": 751.3589743589744,
            "min": 751.3589743589744,
            "max": 971.0666666666667,
            "count": 2
        },
        "Ghost.Environment.EpisodeLength.sum": {
            "value": 29303.0,
            "min": 29132.0,
            "max": 29303.0,
            "count": 2
        },
        "Ghost.Environment.CumulativeReward.mean": {
            "value": 762.863911255812,
            "min": 586.6168744822343,
            "max": 762.863911255812,
            "count": 2
        },
        "Ghost.Environment.CumulativeReward.sum": {
            "value": 29751.69253897667,
            "min": 17598.50623446703,
            "max": 29751.69253897667,
            "count": 2
        },
        "Ghost.Policy.ExtrinsicReward.mean": {
            "value": 762.863911255812,
            "min": 586.6168744822343,
            "max": 762.863911255812,
            "count": 2
        },
        "Ghost.Policy.ExtrinsicReward.sum": {
            "value": 29751.69253897667,
            "min": 17598.50623446703,
            "max": 29751.69253897667,
            "count": 2
        },
        "Ghost.Environment.GroupCumulativeReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 2
        },
        "Ghost.Environment.GroupCumulativeReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 2
        },
        "Ghost.Losses.PolicyLoss.mean": {
            "value": 0.02338887492919134,
            "min": 0.02260808528323347,
            "max": 0.02338887492919134,
            "count": 2
        },
        "Ghost.Losses.PolicyLoss.sum": {
            "value": 0.07016662478757402,
            "min": 0.04521617056646694,
            "max": 0.07016662478757402,
            "count": 2
        },
        "Ghost.Losses.ValueLoss.mean": {
            "value": 8588.618484157987,
            "min": 4236.255788167317,
            "max": 8588.618484157987,
            "count": 2
        },
        "Ghost.Losses.ValueLoss.sum": {
            "value": 25765.85545247396,
            "min": 8472.511576334635,
            "max": 25765.85545247396,
            "count": 2
        },
        "Ghost.Losses.BaselineLoss.mean": {
            "value": 8997.511691623264,
            "min": 4288.496710205078,
            "max": 8997.511691623264,
            "count": 2
        },
        "Ghost.Losses.BaselineLoss.sum": {
            "value": 26992.53507486979,
            "min": 8576.993420410156,
            "max": 26992.53507486979,
            "count": 2
        },
        "Ghost.Policy.LearningRate.mean": {
            "value": 0.0002975343408218866,
            "min": 0.0002975343408218866,
            "max": 0.00029907525030825,
            "count": 2
        },
        "Ghost.Policy.LearningRate.sum": {
            "value": 0.0008926030224656599,
            "min": 0.0005981505006165,
            "max": 0.0008926030224656599,
            "count": 2
        },
        "Ghost.Policy.Epsilon.mean": {
            "value": 0.19917811333333332,
            "min": 0.19917811333333332,
            "max": 0.19969175,
            "count": 2
        },
        "Ghost.Policy.Epsilon.sum": {
            "value": 0.5975343399999999,
            "min": 0.3993835,
            "max": 0.5975343399999999,
            "count": 2
        },
        "Ghost.Policy.Beta.mean": {
            "value": 0.004958987855333333,
            "min": 0.004958987855333333,
            "max": 0.004984618324999999,
            "count": 2
        },
        "Ghost.Policy.Beta.sum": {
            "value": 0.014876963565999997,
            "min": 0.009969236649999998,
            "max": 0.014876963565999997,
            "count": 2
        },
        "Ghost.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        },
        "Ghost.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1747055644",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\benat.ramirez\\AppData\\Local\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn configuration.yaml --run-id=16",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.7.0+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1747056128"
    },
    "total": 483.33348169999954,
    "count": 1,
    "self": 0.3106296999994811,
    "children": {
        "run_training.setup": {
            "total": 0.0629097000000911,
            "count": 1,
            "self": 0.0629097000000911
        },
        "TrainerController.start_learning": {
            "total": 482.95994229999997,
            "count": 1,
            "self": 0.9493333995633293,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.632090600000083,
                    "count": 1,
                    "self": 7.632090600000083
                },
                "TrainerController.advance": {
                    "total": 474.267022300437,
                    "count": 71986,
                    "self": 1.131117900422396,
                    "children": {
                        "env_step": {
                            "total": 389.35802669970144,
                            "count": 71986,
                            "self": 276.3108717993182,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 112.49243360019136,
                                    "count": 71986,
                                    "self": 4.3514182004691975,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 108.14101539972216,
                                            "count": 143822,
                                            "self": 108.14101539972216
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.5547213001918863,
                                    "count": 71985,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 473.4839943998213,
                                            "count": 71985,
                                            "is_parallel": true,
                                            "self": 253.06770830011737,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0003429000007599825,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.0001441000040358631,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0001987999967241194,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0001987999967241194
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 220.41594319970318,
                                                    "count": 71985,
                                                    "is_parallel": true,
                                                    "self": 4.4271444998412335,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 2.2715113999129244,
                                                            "count": 71985,
                                                            "is_parallel": true,
                                                            "self": 2.2715113999129244
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 197.92449670012684,
                                                            "count": 71985,
                                                            "is_parallel": true,
                                                            "self": 197.92449670012684
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 15.792790599822183,
                                                            "count": 143970,
                                                            "is_parallel": true,
                                                            "self": 7.067231999924843,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 8.72555859989734,
                                                                    "count": 287940,
                                                                    "is_parallel": true,
                                                                    "self": 8.72555859989734
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 83.77787770031318,
                            "count": 143970,
                            "self": 1.570116600521942,
                            "children": {
                                "process_trajectory": {
                                    "total": 26.36083309978494,
                                    "count": 143970,
                                    "self": 26.36083309978494
                                },
                                "_update_policy": {
                                    "total": 55.8469280000063,
                                    "count": 14,
                                    "self": 16.020483499989496,
                                    "children": {
                                        "TorchPOCAOptimizer.update": {
                                            "total": 39.826444500016805,
                                            "count": 420,
                                            "self": 39.826444500016805
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.999998731771484e-07,
                    "count": 1,
                    "self": 6.999998731771484e-07
                },
                "TrainerController._save_models": {
                    "total": 0.11149529999966035,
                    "count": 1,
                    "self": 0.004207699999824399,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.10728759999983595,
                            "count": 2,
                            "self": 0.10728759999983595
                        }
                    }
                }
            }
        }
    }
}